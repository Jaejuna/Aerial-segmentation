{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting dataset ready\n",
    "\n",
    "# Cats vs Dogs Dataset\n",
    "tfds.disable_progress_bar()\n",
    " \n",
    "splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n",
    " \n",
    "# load the dataset given the splits defined above\n",
    "splits, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True, split = splits)\n",
    " \n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    " \n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes\n",
    " \n",
    "BATCH_SIZE = 32\n",
    " \n",
    "def normalize_and_resize(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    " \n",
    "    return image, label\n",
    " \n",
    "# prepare batches\n",
    "train_batches = train_examples.shuffle(num_examples // 4).map(normalize_and_resize).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "validation_batches = validation_examples.map(normalize_and_resize).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_batches = test_examples.map(normalize_and_resize).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling and training\n",
    "def build_model():\n",
    "    base_model = tf.keras.applications.VGG16(input_shape= (224, 224, 3),\n",
    "                                             weights='imagenet',\n",
    "                                             include_top=False)\n",
    "    \n",
    "    # add a GAP layer\n",
    "    output = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    " \n",
    "    # output has two neurons for the 2 classes(dogs and cats)\n",
    "    output = tf.keras.layers.Dense(2, activation='softmax')(output)\n",
    " \n",
    "    # set the inputs and outputs of the model\n",
    "    model = tf.keras.Model(base_model.input, output)\n",
    " \n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    " \n",
    "    return model\n",
    "    \n",
    "model = build_model()\n",
    "\n",
    "EPOCHS = 10\n",
    "model.fit(train_batches, epochs=EPOCHS, validation_data=validation_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAM\n",
    "cam_model = tf.keras.Model(model.input, outputs=(model.layers[-3].output, model.layers[-1].output))\n",
    "cam_model.summary()\n",
    "\n",
    "gap_weights = model.layers[-1].get_weights()[0]\n",
    "gap_weights.shape\n",
    "\n",
    "#CAM을 나타내는 함수\n",
    "def show_cam(image_value, features, results, label):\n",
    "    '''\n",
    "    Displays the class activation map of an image\n",
    " \n",
    "    Args:\n",
    "        image_value (tensor) -- preprocessed input image with size 224 x 224\n",
    "        features (array) -- features of the image, shape (1, 7, 7, 512)\n",
    "        results (array) -- output of the sigmoid layer\n",
    "    '''\n",
    "    features_for_img = features[0]\n",
    "    prediction = results[0]\n",
    " \n",
    "    class_activation_weigths = gap_weights[:,label]\n",
    "    class_activation_features = sp.ndimage.zoom(features_for_img, (224/7, 224/7, 1), order=2)\n",
    "    cam_output = np.dot(class_activation_features, class_activation_weigths)\n",
    "    cam_output = tf.reshape(cam_output, (224,224))\n",
    " \n",
    "    # visualize the results\n",
    "    print(f'sigmoid output: {results}')\n",
    "    print(f\"prediction: {'dog' if tf.argmax(results[0]) else 'cat'}\")\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cam_output, cmap='jet', alpha=0.5)\n",
    "    plt.imshow(tf.squeeze(image_value), alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the test images\n",
    "augmented_test_data = test_examples.map(normalize_and_resize)\n",
    "test_batches = augmented_test_data.batch(1)\n",
    "\n",
    "for img, lbl in test_batches.take(5):\n",
    "    print(f\"ground truth: {'dog' if lbl else 'cat'}\")\n",
    "    features,results = cam_model.predict(img)\n",
    "    show_cam(img, features, results, lbl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4 (default, Nov  4 2020, 10:17:35) \n[GCC 7.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
