{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Convolution2D,BatchNormalization,ReLU,LeakyReLU,Add,Activation\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,AveragePooling2D,UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing dataset\n",
    "train_folder=\"/kaggle/input/cityscapes-image-pairs/cityscapes_data/cityscapes_data/train/\"\n",
    "valid_folder=\"/kaggle/input/cityscapes-image-pairs/cityscapes_data/cityscapes_data/val/\"\n",
    "\n",
    "def get_images_masks(path):\n",
    "    names=os.listdir(path)\n",
    "    img_g,img_m=[],[]\n",
    "    for name in names:\n",
    "        img=cv2.imread(path+name)\n",
    "        img=cv2.normalize(img,None,0,1,cv2.NORM_MINMAX,cv2.CV_32F)\n",
    "        img=img[:,:,::-1]\n",
    "        img_g.append(img[:,:256])\n",
    "        img_m.append(np.reshape(img[:,256:],(256*256*3)))\n",
    "        del img\n",
    "    del names\n",
    "    return img_g,img_m\n",
    "        \n",
    "train_imgs,train_masks=get_images_masks(train_folder)\n",
    "valid_imgs,valid_masks=get_images_masks(valid_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(X,filters,block):\n",
    "    # resiudal block with dilated convolutions\n",
    "    # add skip connection at last after doing convoluion operation to input X\n",
    "    \n",
    "    b = 'block_'+str(block)+'_'\n",
    "    f1,f2,f3 = filters\n",
    "    X_skip = X\n",
    "    # block_a\n",
    "    X = Convolution2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n",
    "                      padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n",
    "    X = BatchNormalization(name=b+'batch_norm_a')(X)\n",
    "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n",
    "    # block_b\n",
    "    X = Convolution2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n",
    "                      padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n",
    "    X = BatchNormalization(name=b+'batch_norm_b')(X)\n",
    "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n",
    "    # block_c\n",
    "    X = Convolution2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n",
    "                      padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n",
    "    X = BatchNormalization(name=b+'batch_norm_c')(X)\n",
    "    # skip_conv\n",
    "    X_skip = Convolution2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n",
    "    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n",
    "    # block_c + skip_conv\n",
    "    X = Add(name=b+'add')([X,X_skip])\n",
    "    X = ReLU(name=b+'relu')(X)\n",
    "    return X\n",
    "    \n",
    "def base_feature_maps(input_layer):\n",
    "    # base covolution module to get input image feature maps \n",
    "    \n",
    "    # block_1\n",
    "    base = conv_block(input_layer,[32,32,64],'1')\n",
    "    # block_2\n",
    "    base = conv_block(base,[64,64,128],'2')\n",
    "    # block_3\n",
    "    base = conv_block(base,[128,128,256],'3')\n",
    "    return base\n",
    "\n",
    "def pyramid_feature_maps(input_layer):\n",
    "    # pyramid pooling module\n",
    "    \n",
    "    base = base_feature_maps(input_layer)\n",
    "    # red\n",
    "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
    "    red = tf.keras.layers.Reshape((1,1,256))(red)\n",
    "    red = Convolution2D(filters=64,kernel_size=(1,1),name='red_1_by_1')(red)\n",
    "    red = UpSampling2D(size=256,interpolation='bilinear',name='red_upsampling')(red)\n",
    "    # yellow\n",
    "    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n",
    "    yellow = Convolution2D(filters=64,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n",
    "    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n",
    "    # blue\n",
    "    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n",
    "    blue = Convolution2D(filters=64,kernel_size=(1,1),name='blue_1_by_1')(blue)\n",
    "    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n",
    "    # green\n",
    "    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n",
    "    green = Convolution2D(filters=64,kernel_size=(1,1),name='green_1_by_1')(green)\n",
    "    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n",
    "    # base + red + yellow + blue + green\n",
    "    return tf.keras.layers.concatenate([base,red,yellow,blue,green])\n",
    "\n",
    "def last_conv_module(input_layer):\n",
    "    X = pyramid_feature_maps(input_layer)\n",
    "    X = Convolution2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n",
    "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
    "    X = Activation('sigmoid',name='last_conv_relu')(X)\n",
    "    X = tf.keras.layers.Flatten(name='last_conv_flatten')(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.Input(shape=np.squeeze(train_imgs[0]).shape,name='input')\n",
    "output_layer = last_conv_module(input_layer)\n",
    "model = tf.keras.Model(inputs=input_layer,outputs=output_layer)\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.4 (default, Nov  4 2020, 10:17:35) \n[GCC 7.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
